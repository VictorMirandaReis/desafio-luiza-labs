# Desafio LuizaLabs

Uma API REST que recebe arquivos legados com pedidos desnormalizados, processa e retorna os dados em formato JSON normalizado.

---

## ğŸ”§ Tecnologias e DecisÃµes

### Linguagem

- **Python**: A linguagem escolhida para desenvolver o desafio foi o [Python](https://www.python.org/), por sua simplicidade e facilidade de uso, alÃ©m da sua alta performance, escalabilidade e capacidade de facilitar a normalizaÃ§Ã£o de dados.

### Framework Web

- **FastAPI**: A escolha pelo [FastAPI](https://fastapi.tiangolo.com/) se deu por ser um framework de alta performance, com sintaxe simples e clara, validaÃ§Ã£o automÃ¡tica de dados e geraÃ§Ã£o de documentaÃ§Ã£o interativa. Ele se mostra ideal para as necessidades deste projeto, que envolve a construÃ§Ã£o de uma API moderna e eficiente.

### Servidor

- **Uvicorn**: Servidor ASGI leve e compatÃ­vel com aplicaÃ§Ãµes FastAPI. Recomendado pela prÃ³pria documentaÃ§Ã£o do framework.

### Banco de Dados

- **PostgreSQL**: Escolhido por ser robusto, confiÃ¡vel e amplamente usado. Em alternativa, bancos como SQLite poderiam ser utilizados, mas optei pelo PostgreSQL para demonstrar uma estrutura mais prÃ³xima do real em produÃ§Ã£o.

### ORM

- **SQLAlchemy 2.x**: Utilizado para mapeamento objeto-relacional. Permite manter o projeto desacoplado e alinhado com boas prÃ¡ticas.

### Docker

- O projeto estÃ¡ pronto para ser executado em containers Docker, incluindo o banco de dados e a aplicaÃ§Ã£o web.

---

## ğŸ“ Estrutura de Pastas

```bash
.
â”œâ”€â”€ samples/            # Arquivos de exemplo usados para testes manuais
â”œâ”€â”€ src/                # CÃ³digo-fonte principal da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ api/            # Camada de apresentaÃ§Ã£o e controladores HTTP
â”‚   â”‚   â”œâ”€â”€ controllers/    # Controladores organizados por domÃ­nio
â”‚   â”‚   â”‚   â””â”€â”€ formatters/ # FunÃ§Ãµes auxiliares para saÃ­da de dados
â”‚   â”‚   â””â”€â”€ utils/          # ValidaÃ§Ãµes, respostas padrÃ£o e handlers
â”‚   â”œâ”€â”€ core/           # LÃ³gica de negÃ³cio da aplicaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ order/       # Funcionalidades especÃ­ficas do domÃ­nio "orders"
â”‚   â”œâ”€â”€ db/             # IntegraÃ§Ã£o com banco de dados (SQLAlchemy)
â”œâ”€â”€ tests/              # Testes automatizados (pytest)
```

- Como o projeto Ã© pequeno, optei por manter os models e definiÃ§Ãµes de tabelas em um Ãºnico arquivo. PorÃ©m, seria possÃ­vel utilizar uma ferramenta de migraÃ§Ã£o para versionamento de banco.

- Implementei um pequeno script entrypoint.sh para organizar os comandos de inicializaÃ§Ã£o do sistema, como a criaÃ§Ã£o das tabelas e o start do servidor.

- As exceÃ§Ãµes sÃ£o lanÃ§adas diretamente, pois os controllers jÃ¡ sÃ£o responsÃ¡veis por capturÃ¡-las e tratÃ¡-las por meio de handlers personalizados.

- Apesar de nÃ£o ser um requisito do desafio, incluÃ­ funcionalidades extras como paginaÃ§Ã£o e filtragem por usuÃ¡rio para tornar a API mais completa e flexÃ­vel.

### ğŸ“ Modelagem do Banco de Dados
<img src="docs/modelagem.png" width="350" />

- Embora o desafio nÃ£o exigisse explicitamente, optei por incluir campos como external_id, external_order_id e external_product_id para separar os identificadores internos (usados pelo banco de dados) dos identificadores externos (vindos do arquivo legado ou sistemas externos). Isso facilita a organizaÃ§Ã£o e rastreabilidade dos dados importados, evita conflitos de ID interno do banco de dados em integraÃ§Ãµes externas e permite maior flexibilidade para futuras adaptaÃ§Ãµes ou migraÃ§Ãµes.

## ğŸ“ ObservaÃ§Ãµes

Embora nÃ£o esteja especificado explicitamente no documento do desafio, tomei a decisÃ£o de ignorar produtos com ID igual a zero, assumindo que esses registros nÃ£o sÃ£o vÃ¡lidos para o contexto da aplicaÃ§Ã£o.

## ğŸš€ Executando o Projeto

### âœ… PrÃ©-requisitos

- [Docker](https://www.docker.com/) instalado  
- [Docker Compose](https://docs.docker.com/compose/) instalado  
- [Make](https://www.gnu.org/software/make/) instalado (apenas para Linux/macOS)  


> ğŸ’¡ **UsuÃ¡rios Windows:**  
Se estiver utilizando Windows, os comandos `make` podem nÃ£o funcionar diretamente. Neste caso, recomenda-se executar os comandos equivalentes manualmente via terminal ou usar o WSL (Windows Subsystem for Linux).

---

### â–¶ï¸ Como iniciar o projeto?

Execute o comando `make start` para inicializar os containers da aplicaÃ§Ã£o:

- API Python (FastAPI)  
- Banco de dados PostgreSQL  

Para parar e remover os containers, use `make down`.

Alternativamente, vocÃª pode usar diretamente os comandos do Docker Compose:

```bash
docker-compose up --build
docker-compose down
```

### ğŸ“¡ Endpoints DisponÃ­veis

#### `POST /orders`: Realiza o upload de um arquivo legado contendo pedidos para processamento.

#### `GET /orders`: Lista todos os pedidos processados. 
 
ParÃ¢metros opcionais:
- `user_id`: filtra os pedidos por ID de usuÃ¡rio
- `date`: filtra os pedidos por data (formato `YYYY-MM-DD`)

#### `GET /orders/{id}`: Retorna os detalhes de um pedido especÃ­fico pelo ID.

## âœ… Checklist do Desafio

- Upload de arquivo via API
- Retorno dos dados em JSON normalizado
- Filtros por ID do pedido, `user_id` e data de compra
- Testes automatizados implementados
- DocumentaÃ§Ã£o clara e completa da API

## ğŸ”§ Melhorias futuras do projeto

Como o escopo do projeto Ã© pequeno, optei por nÃ£o implementar algumas funcionalidades neste momento. No entanto, jÃ¡ considero as seguintes melhorias para versÃµes futuras:

- ImplementaÃ§Ã£o de cache para otimizar o desempenho da API.

- CriaÃ§Ã£o de testes completos de ponta a ponta (E2E), incluindo simulaÃ§Ãµes de envio de arquivos, listagem de pedidos e fluxos completos.

- AdiÃ§Ã£o de autenticaÃ§Ã£o por token (como JWT), garantindo maior seguranÃ§a no acesso aos endpoints.